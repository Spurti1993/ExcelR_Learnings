{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. \n",
    "The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n",
    "\n",
    "\n",
    "\n",
    "Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.\n",
    "\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "The explanations of sensor measurements and their brief statistics are given below.\n",
    "\n",
    "Variable (Abbr.) Unit Min Max Mean\n",
    "Ambient temperature (AT) C â€“6.23 37.10 17.71\n",
    "Ambient pressure (AP) mbar 985.85 1036.56 1013.07\n",
    "Ambient humidity (AH) (%) 24.08 100.20 77.87\n",
    "Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93\n",
    "Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56\n",
    "Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43\n",
    "Turbine after temperature (TAT) C 511.04 550.61 546.16\n",
    "Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06\n",
    "Turbine energy yield (TEY) MWH 100.02 179.50 133.51\n",
    "Carbon monoxide (CO) mg/m3 0.00 44.10 2.37\n",
    "Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gas_turbines.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=2\n",
    "label_encoder = LabelEncoder()\n",
    "df['TEY_Label'] = label_encoder.fit_transform(pd.cut(df.TEY, n_bins, retbins=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>TEY_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  TEY_Label  \n",
       "0      3.1547  82.722          0  \n",
       "1      3.2363  82.776          0  \n",
       "2      3.2012  82.468          0  \n",
       "3      3.1923  82.670          0  \n",
       "4      3.2484  82.311          0  \n",
       "...       ...     ...        ...  \n",
       "15034  4.5186  79.559          0  \n",
       "15035  4.8470  79.917          0  \n",
       "15036  7.9632  90.912          0  \n",
       "15037  6.2494  93.227          0  \n",
       "15038  4.9816  92.498          0  \n",
       "\n",
       "[15039 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat((df.iloc[:,0:7],df.iloc[:,8:11]),axis=1,join='inner')\n",
    "Y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_X_train = StandardScaler().fit_transform(X_train)\n",
    "std_X_tst = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "      <td>1.052700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.419550e-16</td>\n",
       "      <td>2.997128e-15</td>\n",
       "      <td>3.483276e-16</td>\n",
       "      <td>3.364945e-16</td>\n",
       "      <td>-4.940582e-16</td>\n",
       "      <td>-8.177412e-15</td>\n",
       "      <td>1.260636e-15</td>\n",
       "      <td>2.522074e-16</td>\n",
       "      <td>5.687823e-17</td>\n",
       "      <td>-4.875194e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "      <td>1.000048e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.282476e+00</td>\n",
       "      <td>-4.232471e+00</td>\n",
       "      <td>-3.519588e+00</td>\n",
       "      <td>-2.756004e+00</td>\n",
       "      <td>-1.813832e+00</td>\n",
       "      <td>-5.046212e+00</td>\n",
       "      <td>-4.177349e+00</td>\n",
       "      <td>-2.000917e+00</td>\n",
       "      <td>-8.746222e-01</td>\n",
       "      <td>-3.885112e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.298847e-01</td>\n",
       "      <td>-6.634794e-01</td>\n",
       "      <td>-6.874094e-01</td>\n",
       "      <td>-6.281935e-01</td>\n",
       "      <td>-5.084421e-01</td>\n",
       "      <td>-2.308800e-01</td>\n",
       "      <td>-4.266342e-01</td>\n",
       "      <td>-4.233955e-01</td>\n",
       "      <td>-4.960015e-01</td>\n",
       "      <td>-6.648438e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.245242e-02</td>\n",
       "      <td>-5.406316e-02</td>\n",
       "      <td>2.285600e-01</td>\n",
       "      <td>-2.071820e-02</td>\n",
       "      <td>-8.617707e-02</td>\n",
       "      <td>2.913376e-01</td>\n",
       "      <td>5.740218e-01</td>\n",
       "      <td>-7.295626e-02</td>\n",
       "      <td>-2.622312e-01</td>\n",
       "      <td>-1.483386e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.040117e-01</td>\n",
       "      <td>5.866052e-01</td>\n",
       "      <td>7.919550e-01</td>\n",
       "      <td>4.612043e-01</td>\n",
       "      <td>4.299379e-01</td>\n",
       "      <td>7.467599e-01</td>\n",
       "      <td>5.943268e-01</td>\n",
       "      <td>4.381766e-01</td>\n",
       "      <td>8.604582e-02</td>\n",
       "      <td>5.388117e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.264903e+00</td>\n",
       "      <td>3.274287e+00</td>\n",
       "      <td>1.537791e+00</td>\n",
       "      <td>4.496416e+00</td>\n",
       "      <td>2.866442e+00</td>\n",
       "      <td>1.026086e+00</td>\n",
       "      <td>6.653943e-01</td>\n",
       "      <td>2.675177e+00</td>\n",
       "      <td>1.857112e+01</td>\n",
       "      <td>4.979092e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.052700e+04  1.052700e+04  1.052700e+04  1.052700e+04  1.052700e+04   \n",
       "mean   1.419550e-16  2.997128e-15  3.483276e-16  3.364945e-16 -4.940582e-16   \n",
       "std    1.000048e+00  1.000048e+00  1.000048e+00  1.000048e+00  1.000048e+00   \n",
       "min   -2.282476e+00 -4.232471e+00 -3.519588e+00 -2.756004e+00 -1.813832e+00   \n",
       "25%   -8.298847e-01 -6.634794e-01 -6.874094e-01 -6.281935e-01 -5.084421e-01   \n",
       "50%    5.245242e-02 -5.406316e-02  2.285600e-01 -2.071820e-02 -8.617707e-02   \n",
       "75%    8.040117e-01  5.866052e-01  7.919550e-01  4.612043e-01  4.299379e-01   \n",
       "max    2.264903e+00  3.274287e+00  1.537791e+00  4.496416e+00  2.866442e+00   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  1.052700e+04  1.052700e+04  1.052700e+04  1.052700e+04  1.052700e+04  \n",
       "mean  -8.177412e-15  1.260636e-15  2.522074e-16  5.687823e-17 -4.875194e-16  \n",
       "std    1.000048e+00  1.000048e+00  1.000048e+00  1.000048e+00  1.000048e+00  \n",
       "min   -5.046212e+00 -4.177349e+00 -2.000917e+00 -8.746222e-01 -3.885112e+00  \n",
       "25%   -2.308800e-01 -4.266342e-01 -4.233955e-01 -4.960015e-01 -6.648438e-01  \n",
       "50%    2.913376e-01  5.740218e-01 -7.295626e-02 -2.622312e-01 -1.483386e-01  \n",
       "75%    7.467599e-01  5.943268e-01  4.381766e-01  8.604582e-02  5.388117e-01  \n",
       "max    1.026086e+00  6.653943e-01  2.675177e+00  1.857112e+01  4.979092e+00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(std_X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-2cc98272f7ba>:15: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasRegressor(build_fn = create_model,verbose = 0)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=350742052864.000, total=  36.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=356515119104.000, total=  29.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=745617883136.000, total=  27.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=336851533824.000, total=  31.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=56053.684, total=  32.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1468652191744.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=759730405376.000, total=  27.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1528233721856.000, total=  29.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1410399862784.000, total=  30.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  4.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1406276730880.000, total=  25.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=580040523776.000, total=  26.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1756760637440.000, total=  26.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1205136523264.000, total=  26.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=2200461115392.000, total=  28.2s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1145522880512.000, total=  26.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2383605137408.000, total=  27.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=3046218924032.000, total=  27.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2755890249728.000, total=  30.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2985700622336.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2320542728192.000, total=  26.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=639999049465856.000, total=  27.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=354881269399552.000, total=  27.2s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=676119523098624.000, total=  26.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=699532799115264.000, total=  25.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=343545105874944.000, total=  25.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1580898407415808.000, total=  28.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1488334748647424.000, total=  27.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=786619770601472.000, total=  28.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1898167507353600.000, total=  26.2s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1990447832498176.000, total=  25.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=1815009558528000.000, total=  27.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=1143302443237376.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=520137048326144.000, total=  28.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=1771094994321408.000, total=  27.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=586749373841408.000, total=  26.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=3531605310177280.000, total=  26.2s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=2734969138970624.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=1166211798794240.000, total=  27.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=1542004928413696.000, total=  30.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=2867354794983424.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=732028862464.000, total=  28.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=1138986319872.000, total=  26.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=1121169833984.000, total=  26.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=1569073135616.000, total=  26.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=369188536320.000, total=  27.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1845070004224.000, total=  28.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1757323067392.000, total=  25.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=2267699740672.000, total=  27.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1180902359040.000, total=  26.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=2165999665152.000, total=  27.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1749782364160.000, total=  26.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1784390090752.000, total=  27.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=544731922432.000, total=  26.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1214480777216.000, total=  26.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1189221236736.000, total=  26.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2419061424128.000, total=  27.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2937922781184.000, total=  27.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=1799037124608.000, total=  26.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2984906850304.000, total=  27.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=1785143099392.000, total=  27.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=1076552141897728.000, total=  32.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=706288245800960.000, total=  32.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=749612252004352.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=1088299682758656.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=729252295081984.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=2253879383162880.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1017117310713856.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=734057021308928.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1479878494912512.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1845181569564672.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1174397872242688.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=555074426241024.000, total= 1.5min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1191008658259968.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=2407931538571264.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1166452451180544.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=1815314635423744.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2867662422016000.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2261875001655296.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2912035608199168.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=1703244443156480.000, total= 2.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=32405362573312.000, total= 5.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=15041477738496.000, total= 4.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=8251039023104.000, total= 5.7min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=16071934345216.000, total= 5.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=14127820963840.000, total= 5.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=30303588450304.000, total= 5.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=31673915801600.000, total= 5.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=38843654864896.000, total= 5.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=24152335450112.000, total= 5.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=23146386161664.000, total= 5.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=25569368473600.000, total= 5.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=12695970512896.000, total= 3.6min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=12715560009728.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=36744032419840.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=37638836846592.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=38766894907392.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=51160853512192.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=37377431044096.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=38973510516736.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=62204132982784.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=7446616445288448.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=1686418.375, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=15068114295193600.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=23502864202596352.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=23789325636337664.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=32170434623438848.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=24545959287455744.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=45422015049367552.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=44838797145276416.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=31023334758023168.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=37847170207973376.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=24177790395875328.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=24831739968880640.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=24943271679623168.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=24716392179695616.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=48232478439112704.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=75772929727528960.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=33624762089472000.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=54803791286894592.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=62444688430333952.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=25205749579776.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=15383835705344.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=16077462437888.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=15571454263296.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=23766191046656.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=16145319985152.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=46479779561472.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=22300139192320.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=45999510781952.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=31034659831808.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=37677982285824.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=50963184353280.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=12291499098112.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=12482204663808.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=37391318384640.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=63216252092416.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=37965438910464.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=84346715242496.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=51415485513728.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=98605528514560.000, total= 1.9min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=7619609674907648.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=23547250542116864.000, total= 2.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=16406185586458624.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=23701676091244544.000, total= 2.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=15548658858590208.000, total= 2.5min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=30550035804454912.000, total= 2.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=40271327059247104.000, total= 2.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=23855635636420608.000, total= 2.5min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=48513141667004416.000, total= 2.6min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=31230188972933120.000, total= 1.8min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=38233502516248576.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1686460.125, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=26021682133073920.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=24710383520448512.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=36013307219410944.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=50835426188984320.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=74281270405758976.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=85658097606983680.000, total=  59.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=51980369980817408.000, total=  59.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=61280606264229888.000, total=  60.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=692232912896.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=337715527680.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=356965580800.000, total=  38.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=363441389568.000, total=  19.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=56053.105, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1057398849536.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=624279224320.000, total=  21.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1424414212096.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1105661788160.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=1794592342016.000, total=  23.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1665992622080.000, total=  23.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1124066525184.000, total=  21.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1633380204544.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=558669955072.000, total=  21.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=1108421771264.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2902020325376.000, total=  21.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2643229409280.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=2817898840064.000, total=  21.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=1781011972096.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=1654943645696.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=1451951946465280.000, total=  25.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=353171469762560.000, total=  20.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=360425904406528.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=711967870287872.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=687487697551360.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=2424234429120512.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1425867267899392.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=1461168409411584.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=3032963096772608.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=2446707577061376.000, total=  21.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=546710044540928.000, total=  21.2s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=1615997014376448.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=571936904052736.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=568282289537024.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=1121995848679424.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=2698502719143936.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=3449350780878848.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=2824509006544896.000, total=  20.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=2258167371137024.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=1693376890011648.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=698181615616.000, total=  20.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=1053008396288.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=717466697728.000, total=  22.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=359400603648.000, total=  20.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=689008476160.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=2113627488256.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=2003366182912.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1479676657664.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1789423517696.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=10, neuron2=8, score=1412983160832.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1644945473536.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=556594757632.000, total=  20.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=572862431232.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=1084580757504.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4, score=666740064256.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=3461719785472.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2834939510784.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2922562977792.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=3279943630848.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8, score=2749437575168.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=1094574629978112.000, total=  20.5s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=729541735612416.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=731497355018240.000, total=  20.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=691765686304768.000, total=  20.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=4, score=707836917055488.000, total=  20.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1835974367641600.000, total=  20.3s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1396699608121344.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1045884129247232.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1403197356769280.000, total=  20.6s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=10, neuron2=8, score=1388648155054080.000, total=  20.7s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1769331641810944.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1081871391784960.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1726931590447104.000, total=  21.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1129918117183488.000, total=  21.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4, score=1091121409163264.000, total=  21.1s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=1259810410463232.000, total=  21.4s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2835837788094464.000, total=  20.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2370175017943040.000, total=  22.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=3905678976483328.000, total=  20.8s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8, score=2857050631569408.000, total=  21.0s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=23031504175104.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=22625791246336.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=22268835004416.000, total= 1.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=168754.453, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=4, score=14635565580288.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=30344501788672.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=21963934269440.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=22262776332288.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=22161901223936.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=10, neuron2=8, score=29840933650432.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=35455529648128.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=11947739185152.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=34333188423680.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=24853600010240.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4, score=11598481588224.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=74164908064768.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=62479216410624.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=49775810445312.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=37950914035712.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8, score=59943537344512.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=22205829176360960.000, total= 1.1min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=30340606756651008.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=14758332262776832.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=6950297540755456.000, total= 1.0min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=4, score=30311123953647616.000, total=  59.9s\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=30331452033859584.000, total= 1.4min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=14812608838238208.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=46423154746195968.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=38105233317953536.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=10, neuron2=8, score=38095702785523712.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=35742964797931520.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=23457208700239872.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=11856717855850496.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=11900461024018432.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4, score=23991075282616320.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=57206421762080768.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=33972291515711488.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=76944674115289088.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=75768875278401536.000, total= 1.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8, score=11450226044829696.000, total= 1.3min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n",
      "[CV]  activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4, score=6454999252992.000, total= 1.2min\n",
      "[CV] activation_function=relu, batch_size=20, dropout_rate=0.2, epochs=300, init=normal, learning_rate=0.01, neuron1=10, neuron2=4 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2cc98272f7ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_X_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Summarize the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [20,40]\n",
    "epochs = [100,300]\n",
    "learning_rate = [0.01,0.1]\n",
    "dropout_rate = [0.1,0.2]\n",
    "activation_function = ['relu','tanh','linear']\n",
    "init = ['uniform','normal']\n",
    "neuron1 = [10,16]\n",
    "neuron2 = [4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(std_X_train,y_train)\n",
    "\n",
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 577us/step - loss: 0.0012 - accuracy: 0.9989\n",
      "accuracy: 99.89%\n",
      "loss: 0.12%\n"
     ]
    }
   ],
   "source": [
    "def model_Creation(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = adam_v2.Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def Train_Test_Validation(X,Y):\n",
    "    batch_size = 40\n",
    "    epochs = 100\n",
    "    learning_rate = 0.01\n",
    "    dropout_rate = 0.1\n",
    "    activation_function = 'relu'\n",
    "    init = 'uniform'\n",
    "    neuron1 = 16\n",
    "    neuron2 =  4\n",
    "    final_model = model_Creation(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2)\n",
    "    #model_classifier = KerasClassifier(build_fn = final_model,verbose = 0,batch_size = batch_size,epochs = epochs)\n",
    "    final_model.fit(X, Y,verbose = 0,batch_size = batch_size,epochs = epochs)\n",
    "    scores = final_model.evaluate(X, Y)\n",
    "    print(\"%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (final_model.metrics_names[0], scores[0]*100))\n",
    "    return final_model\n",
    "\n",
    "final_model = Train_Test_Validation(std_X_train, y_train)\n",
    "#Train_Test_Validation(std_X_tst,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988600740951838\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7723\n",
      "           1       1.00      1.00      1.00      2804\n",
      "\n",
      "    accuracy                           1.00     10527\n",
      "   macro avg       1.00      1.00      1.00     10527\n",
      "weighted avg       1.00      1.00      1.00     10527\n",
      "\n",
      "\n",
      " [[7719    4]\n",
      " [   8 2796]]\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "#pred_train = first_model.predict(np.array(x_train))\n",
    "y_predict = final_model.predict(std_X_train)\n",
    "y_predict = pd.Series([i[0] for i in y_predict])# Printing the metrics o/p is in obj dtype so converting to float so using i[0q]\n",
    "#y_predict\n",
    "#size = [\"small\",\"large\"]\n",
    "#0 for small and 1 for large\n",
    "\n",
    "pred_train_class = pd.Series([0]*10527)\n",
    "pred_train_class[[i>0.5 for i in y_predict]]= 1\n",
    "pred_train_class.unique()\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(accuracy_score(y_train,pred_train_class))\n",
    "print('\\n',classification_report(y_train,pred_train_class))\n",
    "print('\\n',confusion_matrix(y_train,pred_train_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977836879432624\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3342\n",
      "           1       1.00      1.00      1.00      1170\n",
      "\n",
      "    accuracy                           1.00      4512\n",
      "   macro avg       1.00      1.00      1.00      4512\n",
      "weighted avg       1.00      1.00      1.00      4512\n",
      "\n",
      "\n",
      " [[3337    5]\n",
      " [   5 1165]]\n"
     ]
    }
   ],
   "source": [
    "#Testing data\n",
    "y_predict_tst = final_model.predict(std_X_tst)\n",
    "y_predict_tst = pd.Series([i[0] for i in y_predict_tst])# Printing the metrics o/p is in obj dtype so converting to float so using i[0q]\n",
    "#y_predict\n",
    "#size = [\"small\",\"large\"]\n",
    "#0 for small and 1 for large\n",
    "\n",
    "pred_train_class_tst = pd.Series([0]*4512)#len(std_X_train) is 4512 \n",
    "pred_train_class_tst[[i>0.5 for i in y_predict_tst]]= 1\n",
    "pred_train_class_tst.unique()\n",
    "print(accuracy_score(y_test,pred_train_class_tst))\n",
    "print('\\n',classification_report(y_test,pred_train_class_tst))\n",
    "print('\\n',confusion_matrix(y_test,pred_train_class_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4512"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(std_X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
